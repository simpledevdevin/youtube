{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361ab92b-f54f-44ed-afb0-ec2bd2ccf162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ff7be9b-1634-4287-94c9-b8194f057581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streamlit==1.38.0\n",
    "databricks-sdk>=0.26.0\n",
    "databricks-vectorsearch>=0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9481b6f-f448-479a-a433-08fc7b9aab04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999cfaff-cf59-4286-85e0-1a9d8d2a76f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "import streamlit as st\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk.service.serving import ChatMessage, ChatMessageRole\n",
    "\n",
    "# Initialize client\n",
    "w = WorkspaceClient()\n",
    "vsc = VectorSearchClient(\n",
    "    workspace_url=\"https://dbc-123-456.cloud.databricks.com\",\n",
    "    personal_access_token=\"##########################\"\n",
    ")\n",
    "\n",
    "# Get the index\n",
    "index = vsc.get_index(index_name=\"workspace.default.demo_product_texts_vsi\")\n",
    "\n",
    "# COMMAND 2: Define retrieval function\n",
    "def retrieve_products(query: str, k: int = 3):\n",
    "    \"\"\"Perform a vector similarity search against the index.\"\"\"\n",
    "    # Run a similarity search using text\n",
    "    results = index.similarity_search(\n",
    "        query_text = \"comfortable shoes for walking long distances\",\n",
    "        columns = [\"id\",\"name\", \"text\"],   # only return these columns\n",
    "        num_results = 5,\n",
    "        disable_notice=True\n",
    "    )\n",
    "    return results[\"result\"][\"data_array\"]\n",
    "\n",
    "# COMMAND 3: Format retrieved context for RAG\n",
    "def format_context(rows):\n",
    "    formatted = []\n",
    "    for r in rows:\n",
    "        formatted.append(f\"\"\"\n",
    "            Product ID: {r[0]}\n",
    "            Name: {r[1]}\n",
    "            Description: {r[2]}\n",
    "            \"\"\")\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# COMMAND 4: Build RAG prompt\n",
    "def build_prompt(query: str, context: str):\n",
    "    system_prompt = \"\"\"\n",
    "        You are a helpful product expert. You answer customer questions using only the information provided in the retrieved product context.\n",
    "        If the context does not contain the answer, say: \"The catalog does not include that information.\"\n",
    "        Do not make up product details, names, or features.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        User question:\n",
    "        {query}\n",
    "\n",
    "        Here are the retrieved products from the catalog:\n",
    "        {context}\n",
    "\n",
    "        Using ONLY this information, provide the best possible answer.\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "# COMMAND 5: Query LLM endpoint\n",
    "# Replace with your Databricks model serving endpoint\n",
    "MODEL_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "def run_llm(system_prompt, user_prompt):\n",
    "    # client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "    messages = [\n",
    "        ChatMessage(\n",
    "            role=ChatMessageRole.SYSTEM,\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        ChatMessage(\n",
    "            role=ChatMessageRole.USER,\n",
    "            content=user_prompt\n",
    "        )\n",
    "    ]\n",
    "    response = w.serving_endpoints.query(\n",
    "        name=MODEL_ENDPOINT,\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# COMMAND 6: Full RAG pipeline wrapper\n",
    "def rag_answer(query: str):\n",
    "    rows = retrieve_products(query)\n",
    "    context = format_context(rows)\n",
    "    system_prompt, user_prompt = build_prompt(query, context)\n",
    "    answer = run_llm(system_prompt, user_prompt)\n",
    "    return answer, context\n",
    "\n",
    "# --- Streamlit UI ---\n",
    "st.title(\"ðŸ“˜ Product Chatbot\")\n",
    "query = st.text_input(\"Ask a question about our shoes:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "\n",
    "    with st.spinner(\"Retrieving context and generating answer...\"):\n",
    "        answer, retrieved_context = rag_answer(query)\n",
    "\n",
    "    st.subheader(\"Answer:\")\n",
    "    st.write(answer)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Chatbot App Code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
