{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a28822f-4332-4fb8-9464-f3ee53e4a66e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks RAG Demo Notebook\n",
    "---------------------------------------\n",
    "This notebook demonstrates:\n",
    "1. Vector search against a product index\n",
    "2. Retrieval of product name + description\n",
    "3. Construction of a RAG prompt\n",
    "4. Sending prompt to an LLM endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c45f08f-8166-4a55-a924-a723ddc5f337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4577c083-e740-4c2a-b345-b6b6f1f8dfe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "%pip install databricks-sdk\n",
    "%pip install databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48688450-0118-49f0-b955-6186a152c656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import ChatMessage, ChatMessageRole\n",
    "import mlflow\n",
    "import json\n",
    "\n",
    "# Initialize client\n",
    "w = WorkspaceClient()\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "# Get the index\n",
    "index = vsc.get_index(index_name=\"workspace.default.demo_product_texts_vsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0637e55-be7c-4a28-bdc0-0ba94aa936a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# COMMAND 2: Define retrieval function\n",
    "def retrieve_products(query: str, k: int = 3):\n",
    "    \"\"\"Perform a vector similarity search against the index.\"\"\"\n",
    "    # Run a similarity search using text\n",
    "    results = index.similarity_search(\n",
    "        query_text = \"comfortable shoes for walking long distances\",\n",
    "        columns = [\"id\",\"name\", \"text\"],   # only return these columns\n",
    "        num_results = 5,\n",
    "        disable_notice=True\n",
    "    )\n",
    "    return results[\"result\"][\"data_array\"]\n",
    "\n",
    "retrieve_products_test = retrieve_products(\"What shoes are best for rocky trails?\",3)\n",
    "print(retrieve_products_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b484af16-e48c-4078-93b0-2d602f48d550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# COMMAND 3: Format retrieved context for RAG\n",
    "def format_context(rows):\n",
    "    formatted = []\n",
    "    for r in rows:\n",
    "        formatted.append(f\"\"\"\n",
    "            Product ID: {r[0]}\n",
    "            Name: {r[1]}\n",
    "            Description: {r[2]}\n",
    "            \"\"\")\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "format_context_test = format_context(retrieve_products_test)\n",
    "print(format_context_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb194378-2185-4e67-8cd7-75dc92bdfdce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# COMMAND 4: Build RAG prompt\n",
    "def build_prompt(query: str, context: str):\n",
    "    system_prompt = \"\"\"\n",
    "You are a helpful product expert. You answer customer questions using only the information provided in the retrieved product context.\n",
    "If the context does not contain the answer, say: \"The catalog does not include that information.\"\n",
    "Do not make up product details, names, or features.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "User question:\n",
    "{query}\n",
    "\n",
    "Here are the retrieved products from the catalog:\n",
    "{context}\n",
    "\n",
    "Using ONLY this information, provide the best possible answer.\n",
    "\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "query = \"comfortable shoes for walking long distances\"\n",
    "build_prompt_test = build_prompt(query, format_context_test)\n",
    "system_prompt_test = build_prompt_test[0]\n",
    "user_prompt_test = build_prompt_test[1]\n",
    "\n",
    "print(system_prompt_test)\n",
    "print(user_prompt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06918def-add6-427b-be88-4bafb3400ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# COMMAND 5: Query LLM endpoint\n",
    "# Replace with your Databricks model serving endpoint\n",
    "MODEL_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "def run_llm(system_prompt, user_prompt):\n",
    "    # client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "    messages = [\n",
    "        ChatMessage(\n",
    "            role=ChatMessageRole.SYSTEM,\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        ChatMessage(\n",
    "            role=ChatMessageRole.USER,\n",
    "            content=user_prompt\n",
    "        )\n",
    "    ]\n",
    "    response = w.serving_endpoints.query(\n",
    "        name=MODEL_ENDPOINT,\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "run_llm_test = run_llm(system_prompt_test, user_prompt_test)\n",
    "print(run_llm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69400ffd-f811-4a6d-a2fb-f37cc3e6c2ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# COMMAND 6: Full RAG pipeline wrapper\n",
    "def rag_answer(query: str):\n",
    "    rows = retrieve_products(query)\n",
    "    context = format_context(rows)\n",
    "    system_prompt, user_prompt = build_prompt(query, context)\n",
    "    answer = run_llm(system_prompt, user_prompt)\n",
    "    return answer, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41213d79-c1ac-4338-a9cc-e9c3ba200659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# COMMAND 7: Example usage\n",
    "query = \"What are the most comfortable shoes?\"\n",
    "answer, retrieved_context = rag_answer(query)\n",
    "\n",
    "# print(\"Retrieved Context:\\n\", retrieved_context)\n",
    "print(\"\\nRAG Answer:\\n\", answer)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RAG Setup",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
